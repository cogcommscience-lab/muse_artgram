{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee4ed30-4ef5-4cb3-9420-2ee0e0068cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dependencies\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb5e623-de03-4cef-9c6b-09db24fb2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After step 1 is complete\n",
    "# Load in the preprocessed and structured eeg data\n",
    "\n",
    "# This code defines file for opening a pickeled object\n",
    "# Update filename based on epoch duration\n",
    "file = open(\"preprocessed_interpolate_bandpass_.1_20/preprocessed_data_1s_epoch.obj\",'rb')\n",
    "\n",
    "\n",
    "# This code reads in the pickle file\n",
    "preprocess_dict = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4bf0ea-0e3f-4526-bff5-b7324ccd4ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure data as a long dataframe\n",
    "\n",
    "# Initalize empty lists for structuring data\n",
    "eeg_long_df_list = []\n",
    "subj_list = []\n",
    "ses_list = []\n",
    "\n",
    "# For loop that reads in data from preprocess_dict and stores it with the new variables\n",
    "for subj in list(preprocess_dict.keys()):\n",
    "    for ses in list(preprocess_dict[subj].keys()):\n",
    "        temp_df = preprocess_dict[subj][ses]\n",
    "        eeg_long_df_list.append(temp_df)\n",
    "        subj_list.append([subj] * temp_df.shape[0])\n",
    "        ses_list.append([ses] * temp_df.shape[0])\n",
    "        \n",
    "subj_list = [item for sublist in subj_list for item in sublist]\n",
    "ses_list = [item for sublist in ses_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b30a92-d4be-46a2-b9ab-e00b39cccf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a dataframe\n",
    "eeg_long_df = pd.concat(eeg_long_df_list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b437be9-6ac1-4f09-95b5-66a4cd9f315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add subj_list and ses_list to eeg_long_df\n",
    "eeg_long_df[\"subj\"] = subj_list\n",
    "eeg_long_df[\"ses\"] = ses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed79a98e-d128-4732-9b7a-b601f3f8bd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>epoch</th>\n",
       "      <th>time</th>\n",
       "      <th>TP9-1</th>\n",
       "      <th>AF7-1</th>\n",
       "      <th>AF8-1</th>\n",
       "      <th>TP10-1</th>\n",
       "      <th>TP9-2</th>\n",
       "      <th>AF7-2</th>\n",
       "      <th>AF8-2</th>\n",
       "      <th>TP10-2</th>\n",
       "      <th>subj</th>\n",
       "      <th>ses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222848</td>\n",
       "      <td>11.608067</td>\n",
       "      <td>0.223902</td>\n",
       "      <td>0.058120</td>\n",
       "      <td>-0.483754</td>\n",
       "      <td>-5.345793</td>\n",
       "      <td>-0.345295</td>\n",
       "      <td>-0.346974</td>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>-1.673274</td>\n",
       "      <td>-25.432445</td>\n",
       "      <td>-2.610390</td>\n",
       "      <td>0.434157</td>\n",
       "      <td>2.526975</td>\n",
       "      <td>151.898427</td>\n",
       "      <td>2.187296</td>\n",
       "      <td>-2.175046</td>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-3.492170</td>\n",
       "      <td>-54.826924</td>\n",
       "      <td>-4.886415</td>\n",
       "      <td>0.673630</td>\n",
       "      <td>4.259710</td>\n",
       "      <td>290.713836</td>\n",
       "      <td>4.544382</td>\n",
       "      <td>-4.696435</td>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>-5.221177</td>\n",
       "      <td>-70.724021</td>\n",
       "      <td>-6.137424</td>\n",
       "      <td>0.643151</td>\n",
       "      <td>3.749553</td>\n",
       "      <td>396.613306</td>\n",
       "      <td>6.575249</td>\n",
       "      <td>-8.378026</td>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>-6.957718</td>\n",
       "      <td>-70.413833</td>\n",
       "      <td>-6.059825</td>\n",
       "      <td>0.200740</td>\n",
       "      <td>0.575384</td>\n",
       "      <td>462.006339</td>\n",
       "      <td>8.172946</td>\n",
       "      <td>-13.309297</td>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32646907</th>\n",
       "      <td>75003</td>\n",
       "      <td>53755</td>\n",
       "      <td>292</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32646908</th>\n",
       "      <td>75004</td>\n",
       "      <td>53756</td>\n",
       "      <td>292</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32646909</th>\n",
       "      <td>75005</td>\n",
       "      <td>53757</td>\n",
       "      <td>292</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32646910</th>\n",
       "      <td>75006</td>\n",
       "      <td>53758</td>\n",
       "      <td>292</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32646911</th>\n",
       "      <td>75007</td>\n",
       "      <td>53759</td>\n",
       "      <td>292</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32646912 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          level_0  index  epoch      time     TP9-1      AF7-1     AF8-1  \\\n",
       "0               0      0      0  0.000000  0.222848  11.608067  0.223902   \n",
       "1               1      1      0  0.003906 -1.673274 -25.432445 -2.610390   \n",
       "2               2      2      0  0.007812 -3.492170 -54.826924 -4.886415   \n",
       "3               3      3      0  0.011719 -5.221177 -70.724021 -6.137424   \n",
       "4               4      4      0  0.015625 -6.957718 -70.413833 -6.059825   \n",
       "...           ...    ...    ...       ...       ...        ...       ...   \n",
       "32646907    75003  53755    292  0.980469  0.000000   0.000000  0.000000   \n",
       "32646908    75004  53756    292  0.984375  0.000000   0.000000  0.000000   \n",
       "32646909    75005  53757    292  0.988281  0.000000   0.000000  0.000000   \n",
       "32646910    75006  53758    292  0.992188  0.000000   0.000000  0.000000   \n",
       "32646911    75007  53759    292  0.996094  0.000000   0.000000  0.000000   \n",
       "\n",
       "            TP10-1     TP9-2       AF7-2     AF8-2     TP10-2 subj  ses  \n",
       "0         0.058120 -0.483754   -5.345793 -0.345295  -0.346974  001  001  \n",
       "1         0.434157  2.526975  151.898427  2.187296  -2.175046  001  001  \n",
       "2         0.673630  4.259710  290.713836  4.544382  -4.696435  001  001  \n",
       "3         0.643151  3.749553  396.613306  6.575249  -8.378026  001  001  \n",
       "4         0.200740  0.575384  462.006339  8.172946 -13.309297  001  001  \n",
       "...            ...       ...         ...       ...        ...  ...  ...  \n",
       "32646907  0.000000  0.000000    0.000000  0.000000   0.000000  181  003  \n",
       "32646908  0.000000  0.000000    0.000000  0.000000   0.000000  181  003  \n",
       "32646909  0.000000  0.000000    0.000000  0.000000   0.000000  181  003  \n",
       "32646910  0.000000  0.000000    0.000000  0.000000   0.000000  181  003  \n",
       "32646911  0.000000  0.000000    0.000000  0.000000   0.000000  181  003  \n",
       "\n",
       "[32646912 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file for later processing \n",
    "# Update file name depending on epoch duration\n",
    "\n",
    "eeg_long_df.to_csv('preprocessed_interpolate_bandpass_.1_20/eeg_long_df_1s_epoch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "127368a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df\n",
    "# This is where you will store the number of cells rejected by autoreject\n",
    "# Filtered by subj by session by electrode\n",
    "zero_counts_df = pd.DataFrame(columns=['subj', 'ses', 'electrode', 'zero_count', 'nonzero_count', 'total', 'percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0dda454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define electrode columns that you will filter by in eeg_long_df\n",
    "electrodes = ['AF7-1', 'AF8-1', 'TP9-1', 'TP10-1', 'AF7-2', 'AF8-2', 'TP9-2', 'TP10-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0272abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to store results\n",
    "results = []\n",
    "\n",
    "# Count zeros and non-zeros for each subj, ses, and electrode\n",
    "# Calculate total number or rows for each subj for each session for each electrode\n",
    "# Calculate the percentage of rows dropped for each subj for each session for each electrode\n",
    "for (subj, ses), group in eeg_long_df.groupby(['subj', 'ses']):\n",
    "    for electrode in electrodes:\n",
    "        zero_count = (group[electrode] == 0).sum()\n",
    "        nonzero_count = (group[electrode] > 0).sum()\n",
    "        total = zero_count + nonzero_count\n",
    "        percent = (zero_count / total) * 100 if total != 0 else 0  # To handle division by zero\n",
    "\n",
    "        results.append({\n",
    "            'subj': subj,\n",
    "            'ses': ses,\n",
    "            'electrode': electrode,\n",
    "            'zero_count': zero_count,\n",
    "            'nonzero_count': nonzero_count,\n",
    "            'total': total,\n",
    "            'percent': percent\n",
    "        })\n",
    "\n",
    "# Convert list of dicts to DataFrame\n",
    "zero_counts_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e6490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>ses</th>\n",
       "      <th>electrode</th>\n",
       "      <th>zero_count</th>\n",
       "      <th>nonzero_count</th>\n",
       "      <th>total</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>AF7-1</td>\n",
       "      <td>13312</td>\n",
       "      <td>21634</td>\n",
       "      <td>34946</td>\n",
       "      <td>38.093058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>AF8-1</td>\n",
       "      <td>13312</td>\n",
       "      <td>24934</td>\n",
       "      <td>38246</td>\n",
       "      <td>34.806254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>TP9-1</td>\n",
       "      <td>13312</td>\n",
       "      <td>24901</td>\n",
       "      <td>38213</td>\n",
       "      <td>34.836312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>TP10-1</td>\n",
       "      <td>13312</td>\n",
       "      <td>25407</td>\n",
       "      <td>38719</td>\n",
       "      <td>34.381053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>AF7-2</td>\n",
       "      <td>13312</td>\n",
       "      <td>22220</td>\n",
       "      <td>35532</td>\n",
       "      <td>37.464820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "      <td>TP10-1</td>\n",
       "      <td>53760</td>\n",
       "      <td>11817</td>\n",
       "      <td>65577</td>\n",
       "      <td>81.979962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "      <td>AF7-2</td>\n",
       "      <td>30976</td>\n",
       "      <td>22170</td>\n",
       "      <td>53146</td>\n",
       "      <td>58.284725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "      <td>AF8-2</td>\n",
       "      <td>30976</td>\n",
       "      <td>22087</td>\n",
       "      <td>53063</td>\n",
       "      <td>58.375893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "      <td>TP9-2</td>\n",
       "      <td>30976</td>\n",
       "      <td>23596</td>\n",
       "      <td>54572</td>\n",
       "      <td>56.761709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>181</td>\n",
       "      <td>003</td>\n",
       "      <td>TP10-2</td>\n",
       "      <td>30976</td>\n",
       "      <td>23554</td>\n",
       "      <td>54530</td>\n",
       "      <td>56.805428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj  ses electrode  zero_count  nonzero_count  total    percent\n",
       "0     001  001     AF7-1       13312          21634  34946  38.093058\n",
       "1     001  001     AF8-1       13312          24934  38246  34.806254\n",
       "2     001  001     TP9-1       13312          24901  38213  34.836312\n",
       "3     001  001    TP10-1       13312          25407  38719  34.381053\n",
       "4     001  001     AF7-2       13312          22220  35532  37.464820\n",
       "...   ...  ...       ...         ...            ...    ...        ...\n",
       "2595  181  003    TP10-1       53760          11817  65577  81.979962\n",
       "2596  181  003     AF7-2       30976          22170  53146  58.284725\n",
       "2597  181  003     AF8-2       30976          22087  53063  58.375893\n",
       "2598  181  003     TP9-2       30976          23596  54572  56.761709\n",
       "2599  181  003    TP10-2       30976          23554  54530  56.805428\n",
       "\n",
       "[2600 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56cbe386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage of zero counts: 72.11443898783055\n"
     ]
    }
   ],
   "source": [
    "# Get the average number of data dropped:\n",
    "\n",
    "average_percent = zero_counts_df['percent'].mean()\n",
    "print(\"Average percentage of zero counts:\", average_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b60673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv for subsequent processing\n",
    "# Update file path name as necessary\n",
    "\n",
    "df_average_percent = pd.DataFrame({'Average_Percent': [average_percent]})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_average_percent.to_csv('data_dropped/average_percent_1s_epoch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cffbda8-3a6d-48b0-89f7-acb33ee7cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For rejected epochs, autoreject replaces that value with a zero\n",
    "# That creates a problem when trying to calculate ISCs\n",
    "# This is because lots of zeros artifically reduce correlation magnitude\n",
    "# This code replaces zero wit nan to deal with that issue\n",
    "eeg_long_df[[\"TP9-1\", \"AF7-1\", \"AF8-1\", \"TP10-1\", \"TP9-2\", \"AF7-2\", \"AF8-2\", \"TP10-2\"]] = \\\n",
    "eeg_long_df.loc[:, [\"TP9-1\", \"AF7-1\", \"AF8-1\", \"TP10-1\", \"TP9-2\", \"AF7-2\", \"AF8-2\", \"TP10-2\"]].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf4ffded-998a-4b31-88f5-02971999fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure EEG inter-subject correlation\n",
    "# Make a big correlation matrix for each electrode for each pair of participants\n",
    "# Then index that correlation matrix, selecting the correct cell and restructuring as a dataframe\n",
    "\n",
    "corr_df_TP9 = eeg_long_df.groupby([\"subj\", \"ses\"])[[\"TP9-1\", \"TP9-2\"]].corr().iloc[0::2,-1].reset_index().iloc[:,-1]\n",
    "corr_df_AF7 = eeg_long_df.groupby([\"subj\", \"ses\"])[[\"AF7-1\", \"AF7-2\"]].corr().iloc[0::2,-1].reset_index().iloc[:,-1]\n",
    "corr_df_AF8 = eeg_long_df.groupby([\"subj\", \"ses\"])[[\"AF8-1\", \"AF8-2\"]].corr().iloc[0::2,-1].reset_index().iloc[:,-1]\n",
    "corr_df_TP10 = eeg_long_df.groupby([\"subj\", \"ses\"])[[\"TP10-1\", \"TP10-2\"]].corr().iloc[0::2,-1].reset_index().iloc[:,-1]\n",
    "\n",
    "# Combine individual electrode correlation dataframes into one big dataframe \n",
    "corr_df = pd.concat([corr_df_TP9, corr_df_AF7, corr_df_AF8, corr_df_TP10], axis=1)\n",
    "corr_df.columns = [\"TP9\", \"AF7\", \"AF8\", \"TP10\"]\n",
    "corr_df[\"subj\"] = eeg_long_df.groupby([\"subj\", \"ses\"])[[\"TP9-1\", \"TP9-2\"]].corr().iloc[0::2,-1].reset_index().iloc[:,0]\n",
    "corr_df[\"ses\"] = eeg_long_df.groupby([\"subj\", \"ses\"])[[\"TP9-1\", \"TP9-2\"]].corr().iloc[0::2,-1].reset_index().iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63901c1b-d8f7-4ab4-b5cd-914e67e206f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the structured task performance data\n",
    "\n",
    "task_performance_df = pd.read_csv(\"task_performance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50eac86f-357c-4045-b769-86122b073bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'subj' and 'ses' columns of the corr_df dataframe from their current data types to integers\n",
    "corr_df[\"subj\"] = corr_df[\"subj\"].astype(int)\n",
    "corr_df[\"ses\"] = corr_df[\"ses\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d76faf7-a38b-4d7e-abe9-fc52ce13540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'corr_df' dataframe with 'task_performance_df' on columns 'subj' and 'ses', using a left join\n",
    "# This operation adds the columns from 'task_performance_df' to 'corr_df' based on matching 'subj' and 'ses' values\n",
    "# Rows in 'corr_df' that do not match in 'task_performance_df' will be included but have NaN values for the new columns\n",
    "\n",
    "corr_df = corr_df.merge(task_performance_df, on=[\"subj\", \"ses\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f21ae437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the raw self-report data\n",
    "\n",
    "self_report_df = pd.read_csv(\"self_report_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acca1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns \"Q40_participant1\" and \"Q40_participant2\" (these are \"Other\" entries for ethnicity)\n",
    "\n",
    "self_report_df = self_report_df.drop(columns=['Q40_participant1', 'Q40_participant2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "324d6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of cognitive and affective trust for each session\n",
    "\n",
    "for ses in range(1, 4):\n",
    "    # Affective trust columns for this session\n",
    "    \n",
    "    affective_cols = [col for col in self_report_df.columns if 'affecttrust' in col and f'ses{ses}' in col]\n",
    "    self_report_df[f'average_affecttrust_ses{ses}'] = self_report_df[affective_cols].mean(axis=1)\n",
    "    \n",
    "    # Cognitive trust columns for this session\n",
    "    \n",
    "    cognitive_cols = [col for col in self_report_df.columns if 'cognitivetrust' in col and f'ses{ses}' in col]\n",
    "    self_report_df[f'average_cognitivetrust_ses{ses}'] = self_report_df[cognitive_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21c73ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df with unique subj and ses combinations\n",
    "\n",
    "subj_ses_combinations = pd.DataFrame([(s, ses) for s in self_report_df['subj'].unique() for ses in range(1, 4)],\n",
    "                                      columns=['subj', 'ses'])\n",
    "\n",
    "# Merge the averages into this new df\n",
    "\n",
    "for ses in range(1, 4):\n",
    "    subj_ses_combinations = subj_ses_combinations.merge(\n",
    "        self_report_df[['subj', f'average_affecttrust_ses{ses}', f'average_cognitivetrust_ses{ses}']],\n",
    "        on='subj', how='left')\n",
    "\n",
    "    # Assign the values only for the current session\n",
    "    \n",
    "    subj_ses_combinations.loc[subj_ses_combinations['ses'] == ses, 'affective_trust'] = subj_ses_combinations[f'average_affecttrust_ses{ses}']\n",
    "    subj_ses_combinations.loc[subj_ses_combinations['ses'] == ses, 'cognitive_trust'] = subj_ses_combinations[f'average_cognitivetrust_ses{ses}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fdf83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the temporary average columns\n",
    "\n",
    "for ses in range(1, 4):\n",
    "    subj_ses_combinations.drop(columns=[f'average_affecttrust_ses{ses}', f'average_cognitivetrust_ses{ses}'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43ed420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>ses</th>\n",
       "      <th>affective_trust</th>\n",
       "      <th>cognitive_trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>181</td>\n",
       "      <td>3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>471 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj  ses  affective_trust  cognitive_trust\n",
       "0       1    1              2.2         3.250000\n",
       "1       1    2              2.6         3.500000\n",
       "2       1    3              2.6         3.416667\n",
       "3       3    1              2.6         3.583333\n",
       "4       3    2              2.6         4.000000\n",
       "..    ...  ...              ...              ...\n",
       "466   180    2              3.4         4.000000\n",
       "467   180    3              3.7         4.083333\n",
       "468   181    1              2.6         3.750000\n",
       "469   181    2              3.2         3.750000\n",
       "470   181    3              4.1         4.416667\n",
       "\n",
       "[471 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_ses_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1115be5b-86cd-4218-9c5e-89f430c3b890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subj', 'Participant_1', 'Q1_participant1_ses1_affecttrust1', 'Q2_participant1_ses1_affecttrust2', 'Q3_participant1_ses1_affecttrust3', 'Q4_participant1_ses1_affecttrust4', 'Q5_participant1_ses1_affecttrust5', 'Q6_participant1_ses1_cognitivetrust1', 'Q7_participant1_ses1_cognitivetrust2', 'Q8_participant1_ses1_cognitivetrust3', 'Q9_participant1_ses1_cognitivetrust4', 'Q10_participant1_ses1_cognitivetrust5', 'Q11_participant1_ses1_cognitivetrust6', 'Q12_participant1_ses2_affecttrust1', 'Q13_participant1_ses2_affecttrust2', 'Q14_participant1_ses2_affecttrust3', 'Q15_participant1_ses2_affecttrust4', 'Q16_participant1_ses2_affecttrust5', 'Q17_participant1_ses2_cognitivetrust1', 'Q18_participant1_ses2_cognitivetrust2', 'Q19_participant1_ses2_cognitivetrust3', 'Q20_participant1_ses2_cognitivetrust4', 'Q21_participant1_ses2_cognitivetrust5', 'Q22_participant1_ses2_cognitivetrust6', 'Q23_participant1_ses3_affecttrust1', 'Q24_participant1_ses3_affecttrust2', 'Q25_participant1_ses3_affecttrust3', 'Q26_participant1_ses3_affecttrust4', 'Q27_participant1_ses3_affecttrust5', 'Q28_participant1_ses3_cognitivetrust1', 'Q29_participant1_ses3_cognitivetrust2', 'Q30_participant1_ses3_cognitivetrust3', 'Q31_participant1_ses3_cognitivetrust4', 'Q32_participant1_ses3_cognitivetrust5', 'Q33_participant1_ses3_cognitivetrust6', 'Q34_participant1', 'Q35_participant1', 'Q37_participant1', 'Q38_participant1', 'Q39_participant1', 'SC0_participant1', 'Participant_2', 'Q1_participant2_ses1_affecttrust1', 'Q2_participant2_ses1_affecttrust2', 'Q3_participant2_ses1_affecttrust3', 'Q4_participant2_ses1_affecttrust4', 'Q5_participant2_ses1_affecttrust5', 'Q6_participant2_ses1_cognitivetrust1', 'Q7_participant2_ses1_cognitivetrust2', 'Q8_participant2_ses1_cognitivetrust3', 'Q9_participant2_ses1_cognitivetrust4', 'Q10_participant2_ses1_cognitivetrust5', 'Q11_participant2_ses1_cognitivetrust6', 'Q12_participant2_ses2_affecttrust1', 'Q13_participant2_ses2_affecttrust2', 'Q14_participant2_ses2_affecttrust3', 'Q15_participant2_ses2_affecttrust4', 'Q16_participant2_ses2_affecttrust5', 'Q17_participant2_ses2_cognitivetrust1', 'Q18_participant2_ses2_cognitivetrust2', 'Q19_participant2_ses2_cognitivetrust3', 'Q20_participant2_ses2_cognitivetrust4', 'Q21_participant2_ses2_cognitivetrust5', 'Q22_participant2_ses2_cognitivetrust6', 'Q23_participant2_ses3_affecttrust1', 'Q24_participant2_ses3_affecttrust2', 'Q25_participant2_ses3_affecttrust3', 'Q26_participant2_ses3_affecttrust4', 'Q27_participant2_ses3_affecttrust5', 'Q28_participant2_ses3_cognitivetrust1', 'Q29_participant2_ses3_cognitivetrust2', 'Q30_participant2_ses3_cognitivetrust3', 'Q31_participant2_ses3_cognitivetrust4', 'Q32_participant2_ses3_cognitivetrust5', 'Q33_participant2_ses3_cognitivetrust6', 'Q34_participant2', 'Q35_participant2', 'Q37_participant2', 'Q38_participant2', 'Q39_participant2', 'SC0_participant2', 'average_affecttrust_ses1', 'average_cognitivetrust_ses1', 'average_affecttrust_ses2', 'average_cognitivetrust_ses2', 'average_affecttrust_ses3', 'average_cognitivetrust_ses3']\n"
     ]
    }
   ],
   "source": [
    "# Print out all column names to understand their structure\n",
    "print(self_report_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e52a56c3-cf26-44f2-9465-b8bce162f961",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subj  ses  correlation_affecttrust_ses1  correlation_cognitivetrust_ses1  \\\n",
      "0     1    1                      0.157243                              NaN   \n",
      "1     1    2                      0.102062                              NaN   \n",
      "2     1    3                     -0.612372                              NaN   \n",
      "3     3    1                           NaN                              NaN   \n",
      "4     3    2                           NaN                              NaN   \n",
      "\n",
      "   correlation_affecttrust_ses2  correlation_cognitivetrust_ses2  \\\n",
      "0                           NaN                              NaN   \n",
      "1                           NaN                              NaN   \n",
      "2                           NaN                              NaN   \n",
      "3                           NaN                              NaN   \n",
      "4                           NaN                              NaN   \n",
      "\n",
      "   correlation_affecttrust_ses3  correlation_cognitivetrust_ses3  \n",
      "0                           NaN                              NaN  \n",
      "1                           NaN                              NaN  \n",
      "2                           NaN                              NaN  \n",
      "3                           NaN                              NaN  \n",
      "4                           NaN                              NaN  \n",
      "Debugging Session 1, Trust Type: cognitivetrust\n",
      "Debugging Session 2, Trust Type: cognitivetrust\n",
      "Debugging Session 3, Trust Type: cognitivetrust\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming self_report_df is loaded\n",
    "\n",
    "# Create DataFrame for subj and ses combinations\n",
    "subj_ses_combinations = pd.DataFrame([(s, ses) for s in self_report_df['subj'].unique() for ses in range(1, 4)],\n",
    "                                      columns=['subj', 'ses'])\n",
    "\n",
    "sessions = range(1, 4)\n",
    "trust_types = [('affecttrust', 5), ('cognitivetrust', 6)]  # Adjust numbers based on actual questions per session\n",
    "\n",
    "for ses in sessions:\n",
    "    for trust_type, num_questions in trust_types:\n",
    "        # Column for storing correlations\n",
    "        correlation_col_name = f\"correlation_{trust_type}_ses{ses}\"\n",
    "        subj_ses_combinations[correlation_col_name] = np.nan  # Initialize with NaNs\n",
    "\n",
    "        for index, row in self_report_df.iterrows():\n",
    "            # Generate column names for participant 1 and participant 2\n",
    "            p1_cols = [f\"Q{i+1}_participant1_ses{ses}_{trust_type}{i+1}\" for i in range(num_questions)]\n",
    "            p2_cols = [f\"Q{i+1}_participant2_ses{ses}_{trust_type}{i+1}\" for i in range(num_questions)]\n",
    "\n",
    "            # Only proceed if all required columns exist in the DataFrame\n",
    "            if all(col in self_report_df.columns for col in p1_cols + p2_cols):\n",
    "                # Extract the data and drop NAs to ensure equal length\n",
    "                p1_values = row[p1_cols].dropna()\n",
    "                p2_values = row[p2_cols].dropna()\n",
    "\n",
    "                # Ensure both have the same length and more than one value to calculate correlation\n",
    "                if len(p1_values) == len(p2_values) and len(p1_values) > 1:\n",
    "                    # Check if there is any variance, as correlation requires variability in data\n",
    "                    if p1_values.std() > 0 and p2_values.std() > 0:\n",
    "                        correlation = np.corrcoef(p1_values, p2_values)[0, 1]\n",
    "                    else:\n",
    "                        correlation = np.nan\n",
    "                else:\n",
    "                    correlation = np.nan\n",
    "\n",
    "                subj_ses_combinations.at[index, correlation_col_name] = correlation\n",
    "\n",
    "# Output the results\n",
    "print(subj_ses_combinations.head())\n",
    "\n",
    "# Additional debug output for sessions with NaN correlations\n",
    "for ses in sessions:\n",
    "    for trust_type, num_questions in trust_types:\n",
    "        # Print sample data to understand why correlations might be NaN\n",
    "        if 'cognitive' in trust_type:  # Adjust according to your focus\n",
    "            print(f\"Debugging Session {ses}, Trust Type: {trust_type}\")\n",
    "            p1_cols = [f\"Q{i+1}_participant1_ses{ses}_{trust_type}{i+1}\" for i in range(num_questions)]\n",
    "            p2_cols = [f\"Q{i+1}_participant2_ses{ses}_{trust_type}{i+1}\" for i in range(num_questions)]\n",
    "\n",
    "            # Check if columns exist\n",
    "            if all(col in self_report_df.columns for col in p1_cols + p2_cols):\n",
    "                # Extract data for the first few rows to check\n",
    "                sample_data = self_report_df.head()[p1_cols + p2_cols]\n",
    "                print(sample_data.describe())\n",
    "                # Check for variance and NaNs in the sample data\n",
    "                print(\"Variance:\\n\", sample_data.var())\n",
    "                print(\"NaN counts:\\n\", sample_data.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9692a679-e387-4eaa-9bff-ef932b7e7f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging Session 1, Trust Type: cognitivetrust\n",
      "Debugging Session 2, Trust Type: cognitivetrust\n",
      "Debugging Session 3, Trust Type: cognitivetrust\n"
     ]
    }
   ],
   "source": [
    "# Additional debug output for sessions with NaN correlations\n",
    "for ses in sessions:\n",
    "    for trust_type, num_questions in trust_types:\n",
    "        # Print sample data to understand why correlations might be NaN\n",
    "        if 'cognitive' in trust_type:  # Adjust according to your focus\n",
    "            print(f\"Debugging Session {ses}, Trust Type: {trust_type}\")\n",
    "            p1_cols = [f\"Q{i+1}_participant1_ses{ses}_{trust_type}{i+1}\" for i in range(num_questions)]\n",
    "            p2_cols = [f\"Q{i+1}_participant2_ses{ses}_{trust_type}{i+1}\" for i in range(num_questions)]\n",
    "\n",
    "            # Check if columns exist\n",
    "            if all(col in self_report_df.columns for col in p1_cols + p2_cols):\n",
    "                # Extract data for the first few rows to check\n",
    "                sample_data = self_report_df.head()[p1_cols + p2_cols]\n",
    "                print(sample_data.describe())\n",
    "                # Check for variance and NaNs in the sample data\n",
    "                print(\"Variance:\\n\", sample_data.var())\n",
    "                print(\"NaN counts:\\n\", sample_data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3384bdcf-aa40-418a-b249-70920a2397c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>ses</th>\n",
       "      <th>correlation_affecttrust_ses1</th>\n",
       "      <th>correlation_cognitivetrust_ses1</th>\n",
       "      <th>correlation_affecttrust_ses2</th>\n",
       "      <th>correlation_cognitivetrust_ses2</th>\n",
       "      <th>correlation_affecttrust_ses3</th>\n",
       "      <th>correlation_cognitivetrust_ses3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>181</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>471 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj  ses  correlation_affecttrust_ses1  correlation_cognitivetrust_ses1  \\\n",
       "0       1    1                           NaN                              NaN   \n",
       "1       1    2                           NaN                              NaN   \n",
       "2       1    3                           NaN                              NaN   \n",
       "3       3    1                           NaN                              NaN   \n",
       "4       3    2                           NaN                              NaN   \n",
       "..    ...  ...                           ...                              ...   \n",
       "466   180    2                           NaN                              NaN   \n",
       "467   180    3                           NaN                              NaN   \n",
       "468   181    1                           NaN                              NaN   \n",
       "469   181    2                           NaN                              NaN   \n",
       "470   181    3                           NaN                              NaN   \n",
       "\n",
       "     correlation_affecttrust_ses2  correlation_cognitivetrust_ses2  \\\n",
       "0                             NaN                              NaN   \n",
       "1                             NaN                              NaN   \n",
       "2                             NaN                              NaN   \n",
       "3                             NaN                              NaN   \n",
       "4                             NaN                              NaN   \n",
       "..                            ...                              ...   \n",
       "466                           NaN                              NaN   \n",
       "467                           NaN                              NaN   \n",
       "468                           NaN                              NaN   \n",
       "469                           NaN                              NaN   \n",
       "470                           NaN                              NaN   \n",
       "\n",
       "     correlation_affecttrust_ses3  correlation_cognitivetrust_ses3  \n",
       "0                             NaN                              NaN  \n",
       "1                             NaN                              NaN  \n",
       "2                             NaN                              NaN  \n",
       "3                             NaN                              NaN  \n",
       "4                             NaN                              NaN  \n",
       "..                            ...                              ...  \n",
       "466                           NaN                              NaN  \n",
       "467                           NaN                              NaN  \n",
       "468                           NaN                              NaN  \n",
       "469                           NaN                              NaN  \n",
       "470                           NaN                              NaN  \n",
       "\n",
       "[471 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_ses_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08868ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'corr_df' dataframe with 'subj_ses_combinations' on columns 'subj' and 'ses', using a left join\n",
    "# This operation adds the columns from 'subj_ses_combinations' to 'corr_df' based on matching 'subj' and 'ses' values\n",
    "# Rows in 'corr_df' that do not match in 'subj_ses_combinations' will be included but have NaN values for the new columns\n",
    "\n",
    "corr_df = corr_df.merge(subj_ses_combinations, on=[\"subj\", \"ses\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af51099-dff2-4b7c-95e5-31024f6fe416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows from the 'corr_df' dataframe that contain any missing values (NaNs)\n",
    "\n",
    "corr_df = corr_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d56f96-d684-4de4-a86d-c61bb1fadd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the unique number of subjects in the 'subj' column of the 'corr_df' dataframe\n",
    "# This is achieved by selecting the 'subj' column, calling .unique() to get an array of unique values,\n",
    "# and then accessing the first element of the .shape attribute, which represents the number of unique subjects\n",
    "\n",
    "corr_df.subj.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89743492-d9fe-4730-8924-26767a32e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the correlation dataframe to a csv file for later analysis\n",
    "# Update filename based on epoch duration\n",
    "\n",
    "corr_df.to_csv(\"preprocessed_interpolate_bandpass_.1_20/merged_corr_df_1s_epoch.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
